{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeaea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json, numpy as np\n",
    "from scanr_utils import *\n",
    "from casuhal_utils import *\n",
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eace86b",
   "metadata": {},
   "source": [
    "## 1. Récupérer les DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2532e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de DOI importés depuis fichier \t500\n"
     ]
    }
   ],
   "source": [
    "## option A : utiliser un fichier local \n",
    "\n",
    "utiliser_fichier_local = True\n",
    "\n",
    "if utiliser_fichier_local : \n",
    "    ## un fichier local placé dans le dossier *data*\n",
    "    ## doit être un fichier .csv avec encodage utf8 et ',' comme séparateur\n",
    "    ## avec au moins une colonne *doi* \n",
    "    ## precier le nom de cette colonne (DOI, doiId_s etc. )\n",
    "    doi_col_name = \"DOI\"\n",
    "    df_mydois = pd.read_csv(\"data/2022-05-05-scopus-sci-ipgp.csv\", usecols=[doi_col_name])\n",
    "    # dans la suite du code la colonne doit être nommée doi\n",
    "    df_mydois.rename(columns = {doi_col_name : \"doi\"}, inplace = True)\n",
    "    ## limiter le nombre de ligne/publication\n",
    "    df_mydois = df_mydois[:500]\n",
    "    #df_mydois = pd.read_csv(\"data/up/2021_12_02_scopus_fac_sh__doi.csv\", usecols=[\"doi\"])         \n",
    "    print(f\"nb de DOI importés depuis fichier \\t{len(df_mydois)}\")\n",
    "else : \n",
    "    df_mydois = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f72220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## option B : utiliser ScanR\n",
    "# les deux options peuvent être valides, un dédoublonnage sera alors effectué\n",
    "\n",
    "utiliser_scanR = False # True pour oui False pour non \n",
    "\n",
    "if utiliser_scanR : \n",
    "    \n",
    "    id_etab = \"180089047\" # identifiant UAI de votre établissement\n",
    "    # UP 0755976N, Nantes 194409843, INRIA 180089047\n",
    "    min_year = 2020 # l'année à partir de laquelle commencer la récupération. \n",
    "    # scanR inclut les publications jusqu'a 2020.\n",
    "    # 2020 donne les publications de 2020. 2019 donne les publications de 2019 et 2020 etc.\n",
    "\n",
    "    df_scanr = get_publications_with_doi(id_etab, min_year)\n",
    "    df_scanr.drop(columns = [\"title\", \"year\"], inplace = True)\n",
    "    print(f\"nb de DOI récupérés de ScanR \\t{len(df_scanr)}\")\n",
    "    #df_scanr.to_csv(\"data\\doi_scanr.csv\", columns= [\"doi\"], index = False)\n",
    "    \n",
    "    # concatener et dédoublonner\n",
    "    df = pd.concat([df_mydois, df_scanr])\n",
    "    df[\"doi\"] = df[\"doi\"].str.lower() # doi en minuscule\n",
    "    df = df[ (~df['doi'].duplicated()) & (df[\"doi\"].notna())].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "else : \n",
    "    df = df_mydois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ceb691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb de DOI a traiter \t500\n",
      " /!\\ temps estimé ~17 minutes\n"
     ]
    }
   ],
   "source": [
    "# retrait des publications sans DOI\n",
    "df.dropna(subset=[\"doi\"], inplace = True)\n",
    "# feedback nb de DOI  et tps de traitement\n",
    "print(f\" nb de DOI a traiter \\t{len(df)}\")\n",
    "print(f\" /!\\ temps estimé ~{round(len(df) * 40/1200)} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d79c13",
   "metadata": {},
   "source": [
    "## 2. Enrichir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1285c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans HAL 500\n",
      "hal 10% \n",
      "hal 20% \n",
      "hal 30% \n",
      "hal 40% \n",
      "hal 50% \n",
      "hal 60% \n",
      "hal 70% \n",
      "hal 80% \n",
      "hal 90% \n",
      "hal 100%\n",
      "nb de DOI après retrait de ceux en TI dans HAL 411\n"
     ]
    }
   ],
   "source": [
    "# 2.1. pour chaque publications déduire la présence dans HAL\n",
    "df_hal = enrich_w_hal(df) # renseigner df[:50].copy() pour tester uniquement sur les 50 premiers DOI\n",
    "#retirer ce qui est déjà déposé avec fichier\n",
    "df_no_file = df_hal[ df_hal[\"submitType\"] != \"file\" ].copy()\n",
    "print(f\"nb de DOI après retrait de ceux en TI dans HAL {len(df_no_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ef3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans upw \t411\n",
      "upw 10% \n",
      "upw 20% \n",
      "upw 30% \n",
      "upw 40% \n",
      "upw 50% \n",
      "upw 60% \n",
      "upw 70% \n",
      "upw 80% \n",
      "upw 90% \n",
      "upw 100% \n",
      "upw 100%\n"
     ]
    }
   ],
   "source": [
    "# 2.2. pour chaque publications ajouter les informations d'accès ouvert via Unpaywall\n",
    "df_upw = enrich_w_upw(df_no_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7c568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer nan/None par des champs vides\n",
    "df_upw[\"oa_repo_link\"].replace(np.nan, \"\", inplace = True)\n",
    "df_upw[\"oa_repo_link\"].replace(\"None\", \"\", inplace = True)\n",
    "df_upw[\"oa_publisher_license\"].replace(np.nan, \"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79cff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doi problem w permissions 10.1038/s41598-022-10647-5\n",
      "10.1515/ijmr-2005-0215 publishedVersion accepted ! ouraaaaah \n",
      "10.1083/jcb.202110044 publishedVersion accepted ! ouraaaaah \n",
      "10.1093/gji/ggac026 publishedVersion accepted ! ouraaaaah \n",
      "10.1093/gji/ggac005 publishedVersion accepted ! ouraaaaah \n",
      "doi problem w permissions 10.1016/j.rinp.2022.105443\n",
      "10.1029/2021GL095557 publishedVersion accepted ! ouraaaaah \n",
      "10.1103/PhysRevB.105.165403 acceptedVersion , no embargo\n",
      "doi problem w permissions 10.1063/5.0081481\n",
      "doi problem w permissions 10.1063/5.0082016\n",
      "doi problem w permissions 10.1063/5.0081408\n",
      "10.1029/2021JB023715 publishedVersion accepted ! ouraaaaah \n",
      "10.1029/2022JB024131 publishedVersion accepted ! ouraaaaah \n",
      "doi problem w permissions 10.3847/1538-4365/ac45f7\n",
      "10.1107/S1600576722001406 acceptedVersion , no embargo\n",
      "doi problem w permissions 10.1515/crelle-2021-0088\n",
      "10.1109/TED.2022.3145767 acceptedVersion , no embargo\n",
      "doi problem w permissions 10.1073/pnas.2115258119\n",
      "10.1029/2021GL097156 publishedVersion accepted ! ouraaaaah \n",
      "10.1063/5.0079588 publishedVersion accepted ! ouraaaaah \n",
      "10.1029/2021JD036140 publishedVersion accepted ! ouraaaaah \n",
      "10.1029/2021GL096990 publishedVersion accepted ! ouraaaaah \n",
      "doi problem w permissions 10.1103/PhysRevD.105.064061\n",
      "10.1103/PhysRevB.105.125420 acceptedVersion , no embargo\n",
      "10.1103/PhysRevB.105.125112 acceptedVersion , no embargo\n",
      "10.1242/dev.200159 publishedVersion accepted ! ouraaaaah \n",
      "10.1063/5.0083282 publishedVersion accepted ! ouraaaaah \n",
      "10.1126/science.abo5791 acceptedVersion , no embargo\n",
      "10.1083/jcb.202011085 publishedVersion accepted ! ouraaaaah \n",
      "10.1103/PhysRevLett.128.094503 acceptedVersion , no embargo\n",
      "10.1182/BLOODADVANCES.2021005983 publishedVersion accepted ! ouraaaaah \n",
      "10.1109/TCDS.2020.2986411 acceptedVersion , no embargo\n",
      "10.1103/PhysRevC.105.034334 acceptedVersion , no embargo\n",
      "10.1103/PhysRevE.105.034504 acceptedVersion , no embargo\n",
      "10.1103/PhysRevC.105.034319 acceptedVersion , no embargo\n",
      "doi problem w permissions 10.4230/LIPIcs.STACS.2022.9\n",
      "doi problem w permissions 10.4230/LIPIcs.STACS.2022.35\n",
      "10.1128/aem.02378-21 acceptedVersion , no embargo\n"
     ]
    }
   ],
   "source": [
    "# 2.2. ajouter les possibilités de dépôt via l'API Permissions\n",
    "df_upw[\"deposit_condition\"] = df_upw.apply(lambda row : add_permissions(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09e3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export des données brutes\n",
    "df_upw.to_csv(\"data/raw__dois_hal_upw_perm.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2a3eb",
   "metadata": {},
   "source": [
    "## 3. Trier et Formater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f25ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI retiré car marqué 'open' dans HAL et repository dans upw 82\n"
     ]
    }
   ],
   "source": [
    "df_final = df_upw\n",
    "df_final.fillna(\"\", inplace = True)# sinon nan sera compris comme une string non vide\n",
    "\n",
    "## retirer ce qui est dans HAL qui a un lien extérieur et qui est signalé en repository dans upw\n",
    "index2remove = df_final[ (df_final[\"linkExtId\"] != \"\") & (df_final[\"oa_repo_link\"] != \"\") ].index\n",
    "df_final.drop(index2remove, inplace = True)\n",
    "print(f\"nb DOI retiré car marqué 'open' dans HAL et repository dans upw {len(index2remove)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b7f56c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques\n",
      "\n",
      "nb de DOI a traiter\t\t\t329\n",
      "creer ou retrouver la notice                                 123\n",
      "ecrire a l auteur pour appliquer la LRN                      119\n",
      "selon la licence ajouter le PDF editeur                       66\n",
      "recuperer le PDF editeur et ecrire a l auteur pour accord     15\n",
      "verifier les identifiants de la notice                         2\n",
      "Name: todo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# deduire la colonne todo\n",
    "df_final[\"todo\"] = df_final.apply(lambda row : deduce_todo(row), axis = 1)\n",
    "df_final.to_csv(\"data\\dois_a_traiter.csv\", index = False)\n",
    "#imprimer des statistiques brutes\n",
    "print(f\"\\nStatistiques\\n\\nnb de DOI a traiter\\t\\t\\t{len(df_final)}\\n{df_final['todo'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40b4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrait des colonnes inutiles \n",
    "df_final.drop(columns= [\"submitType\", \"has_issn\"], inplace = True)\n",
    "\n",
    "# rendre la lecture dans libreOffice plus élégante avec l'ajout d'hyperlien\n",
    "df_final[\"doi\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://doi.org/\", row[\"doi\"], row[\"doi\"]), axis = 1)  \n",
    "df_final[\"halId\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://hal.archives-ouvertes.fr/\", row[\"halId\"], row[\"halId\"]), axis = 1)  \n",
    "df_final[\"oa_publisher_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_publisher_link\"], row[\"oa_publisher_link\"]), axis = 1)\t\n",
    "df_final[\"oa_repo_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_repo_link\"], row[\"oa_repo_link\"]), axis = 1)\t\n",
    "\n",
    "df_final.to_csv(\"data\\dois_a_traiter_formules.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e1cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
