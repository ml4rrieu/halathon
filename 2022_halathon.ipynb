{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeaea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json, numpy as np\n",
    "from scanr_utils import *\n",
    "from casuhal_utils import *\n",
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eace86b",
   "metadata": {},
   "source": [
    "## 1. Récupérer les DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2532e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de DOI importés depuis fichier \t1113\n"
     ]
    }
   ],
   "source": [
    "## option A : utiliser un fichier local \n",
    "\n",
    "utiliser_fichier_local = True # True pour oui False pour non\n",
    "\n",
    "if utiliser_fichier_local : \n",
    "    ## un fichier local placé dans le dossier *data*\n",
    "    ## doit être un fichier .csv avec encodage utf8 et ',' comme séparateur\n",
    "    ## avec au moins une colonne *doi* \n",
    "    #(pour scopus remplacer DOI par doi)\n",
    "    df_mydois = pd.read_csv(\"data/2022-04-sciences-ipgp-scopus.csv\", usecols=[\"doi\"])         \n",
    "    #df_mydois = pd.read_csv(\"data/up/2021_12_02_scopus_fac_sh__doi.csv\", usecols=[\"doi\"])         \n",
    "    print(f\"nb de DOI importés depuis fichier \\t{len(df_mydois)}\")\n",
    "else : \n",
    "    df_mydois = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f72220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## option B : utiliser ScanR\n",
    "# les deux options peuvent être valides, un dédoublonnage sera alors effectué\n",
    "\n",
    "utiliser_scanR = False # True pour oui False pour non \n",
    "\n",
    "if utiliser_scanR : \n",
    "    \n",
    "    id_etab = \"180089047\" # identifiant UAI de votre établissement\n",
    "    # UP 0755976N, Nantes 194409843, INRIA 180089047\n",
    "    min_year = 2020 # l'année à partir de laquelle commencer la récupération. \n",
    "    # scanR inclut les publications jusqu'a 2020.\n",
    "    # 2020 donne les publications de 2020. 2019 donne les publications de 2019 et 2020 etc.\n",
    "\n",
    "    df_scanr = get_publications_with_doi(id_etab, min_year)\n",
    "    df_scanr.drop(columns = [\"title\", \"year\"], inplace = True)\n",
    "    print(f\"nb de DOI récupérés de ScanR \\t{len(df_scanr)}\")\n",
    "    #df_scanr.to_csv(\"data\\doi_scanr.csv\", columns= [\"doi\"], index = False)\n",
    "    \n",
    "    # concatener et dédoublonner\n",
    "    df = pd.concat([df_mydois, df_scanr])\n",
    "    df[\"doi\"] = df[\"doi\"].str.lower() # doi en minuscule\n",
    "    df = df[ (~df['doi'].duplicated()) & (df[\"doi\"].notna())].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "else : \n",
    "    df = df_mydois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ceb691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb de DOI a traiter \t1113\n",
      " /!\\ temps estimé ~37 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\" nb de DOI a traiter \\t{len(df)}\")\n",
    "print(f\" /!\\ temps estimé ~{round(len(df) * 40/1200)} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d79c13",
   "metadata": {},
   "source": [
    "## 2. Enrichir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1285c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans HAL 1113\n",
      "hal 10% \n",
      "hal 20% \n",
      "hal 30% \n",
      "hal 40% \n",
      "hal 50% \n",
      "hal 60% \n",
      "hal 70% \n",
      "hal 80% \n",
      "hal 90% \n",
      "hal 100% \n",
      "hal 100%\n",
      "nb de DOI après retrait de ceux en TI Dans HAL 888\n"
     ]
    }
   ],
   "source": [
    "# 2.1. pour chaque publications déduire la présence dans HAL\n",
    "df_hal = enrich_w_hal(df) # renseigner df[:50].copy() pour tester uniquement sur les 50 premiers DOI\n",
    "#retirer ce qui est déjà déposé avec fichier\n",
    "df_no_file = df_hal[ df_hal[\"submitType\"] != \"file\" ].copy()\n",
    "print(f\"nb de DOI après retrait de ceux en TI Dans HAL {len(df_no_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ef3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans upw \t888\n",
      "upw 10% \n",
      "upw 20% \n",
      "upw 30% \n",
      "upw 40% \n",
      "upw 50% \n",
      "upw 59% \n",
      "upw 69% \n",
      "upw 79% \n",
      "upw 89% \n",
      "upw 99% \n",
      "upw 100%\n"
     ]
    }
   ],
   "source": [
    "# 2.2. pour chaque publications ajouter les informations d'accès ouvert via Unpaywall\n",
    "df_upw = enrich_w_upw(df_no_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer nan/None par des champs vides\n",
    "df_upw[\"oa_repo_link\"].replace(np.nan, \"\", inplace = True)\n",
    "df_upw[\"oa_repo_link\"].replace(\"None\", \"\", inplace = True)\n",
    "df_upw[\"oa_publisher_license\"].replace(np.nan, \"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2. ajouter les possibilités de dépôt via l'API Permissions\n",
    "df_upw[\"deposit_condition\"] = df_upw.apply(lambda row : add_permissions(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export des données brutes\n",
    "df_upw.to_csv(\"data/raw__dois_hal_upw_perm.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2a3eb",
   "metadata": {},
   "source": [
    "## 3. Trier et Formater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f25ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_permissions\n",
    "df_final.fillna(\"\", inplace = True)# sinon nan sera compris comme une string non vide\n",
    "\n",
    "## retirer ce qui est dans HAL qui a un lien extérieur et qui est signalé en repository dans upw\n",
    "index2remove = df_final[ (df_final[\"linkExtId\"] != \"\") & (df_final[\"oa_repo_link\"] != \"\") ].index\n",
    "df_final.drop(index2remove, inplace = True)\n",
    "print(f\"nb DOI retiré car marqué 'open' dans HAL et repository dans upw {len(index2remove)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduire la colonne todo\n",
    "df_final[\"todo\"] = df_final.apply(lambda row : deduce_todo(row), axis = 1)\n",
    "df_final.to_csv(\"data\\dois_a_traiter.csv\", index = False)\n",
    "#imprimer des statistiques brutes\n",
    "print(f\"\\nStatistiques\\n\\nnb de DOI a traiter\\t\\t\\t{len(df_final)}\\n{df_final['todo'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrait des colonnes inutiles \n",
    "df_final.drop(columns= [\"submitType\", \"has_issn\"], inplace = True)\n",
    "\n",
    "# rendre la lecture dans libreOffice plus élégante avec l'ajout d'hyperlien\n",
    "df_final[\"doi\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://doi.org/\", row[\"doi\"], row[\"doi\"]), axis = 1)  \n",
    "df_final[\"halId\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://hal.archives-ouvertes.fr/\", row[\"halId\"], row[\"halId\"]), axis = 1)  \n",
    "df_final[\"oa_publisher_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_publisher_link\"], row[\"oa_publisher_link\"]), axis = 1)\t\n",
    "df_final[\"oa_repo_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_repo_link\"], row[\"oa_repo_link\"]), axis = 1)\t\n",
    "\n",
    "df_final.to_csv(\"data\\dois_a_traiter_formules.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
