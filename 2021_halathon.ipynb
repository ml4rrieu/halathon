{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeaea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanr_utils import *\n",
    "from casuhal_utils import *\n",
    "import pandas as pd, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2532e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de DOI récupérés de ScanR \t0\n"
     ]
    }
   ],
   "source": [
    "# ____1____ RECUPERER LES DOI\n",
    "\n",
    "## utiliser l'API de ScanR\n",
    "\n",
    "id_etab = \"0755976N\" # identifiant UAI de votre établissement (le récupérer sur scanR par ex.)\n",
    "min_year = 2021\n",
    "# scanR inclut des publications jusqu'a 2020. min_year est l'année à partir de laquelle commencer la récupération\n",
    "# renseigner 2021 revient à ne pas utiliser scanR. \n",
    "# choix effectué à UP pour favoriser dans un premier temps les DOI récents (extrait de scopus)\n",
    "df_scanr = get_publications_with_doi(id_etab, min_year)\n",
    "print(f\"nb de DOI récupérés de ScanR \\t{len(df_scanr)}\")\n",
    "#df_scanr.to_csv(\"data\\doi_scanr.csv\", columns= [\"doi\"], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bae7e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de DOI importés depuis fichier \t1283\n"
     ]
    }
   ],
   "source": [
    "# option : ajouter des doi en plus de scanr ? \n",
    "ajout_doi_en_plus_de_scanr = True # True pour oui False pour non\n",
    "\n",
    "if ajout_doi_en_plus_de_scanr : \n",
    "    # fichier csv doit être dans le dossier *data*\n",
    "    # ',' comme séparateur, utf8 pour l'encodage, avec une colonne *doi*\n",
    "    df_mydois = pd.read_csv(\"data\\scopus_2021.csv\", usecols=[\"doi\"]) \n",
    "    print(f\"nb de DOI importés depuis fichier \\t{len(df_mydois)}\")\n",
    "    \n",
    "    # concatener et dédoublonner\n",
    "    df = pd.concat([df_scanr, df_mydois])\n",
    "    df[\"doi\"] = df[\"doi\"].str.lower() # doi en minuscule\n",
    "    df = df[ (~df['doi'].duplicated()) & (df[\"doi\"].notna())].copy()\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ceb691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de DOI a traiter \t1282\n"
     ]
    }
   ],
   "source": [
    "if not ajout_doi_en_plus_de_scanr : \n",
    "    df = df_scanr\n",
    "print(f\"nb de DOI a traiter \\t{len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1285c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans HAL 1282\n",
      "hal 10% \n",
      "hal 20% \n",
      "hal 30% \n",
      "hal 40% \n",
      "hal 50% \n",
      "hal 60% \n",
      "hal 70% \n",
      "hal 80% \n",
      "hal 90% \n",
      "hal 100% \n",
      "hal 100%\n",
      "nb de DOI après retrait de ceux en TI Dans HAL 1113\n"
     ]
    }
   ],
   "source": [
    "# ____2____ ENRICHIR\n",
    "\n",
    "## avec HAL\n",
    "df_hal = enrich_w_hal(df) # renseigner df[:50].copy() pour tester uniquement sur les 50 premiers DOI\n",
    "df_no_file = df_hal[ df_hal[\"submitType\"] != \"file\" ].copy()\n",
    "print(f\"nb de DOI après retrait de ceux en TI Dans HAL {len(df_no_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ef3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans upw \t1113\n",
      "upw 10% \n",
      "upw 20% \n",
      "upw 30% \n",
      "upw 40% \n",
      "upw 50% \n",
      "upw 60% \n",
      "upw 70% \n",
      "upw 80% \n",
      "upw 90% \n",
      "upw 100% \n",
      "upw 100%\n"
     ]
    }
   ],
   "source": [
    "## avec unpaywall\n",
    "df_upw = enrich_w_upw(df_no_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79cff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permissions 100%\n"
     ]
    }
   ],
   "source": [
    "## avec Permissions\n",
    "df_permissions = enrich_w_permissions(df_upw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09e3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## premier export des données brutes\n",
    "df_permissions.to_csv(\"data\\dois_hal_upw_perm.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f25ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI retiré car marqué 'open' dans HAL et repository dans upw 50\n"
     ]
    }
   ],
   "source": [
    "# ____3____ TRIE & FORMATAGE\n",
    "\n",
    "df_final = df_permissions\n",
    "df_final.fillna(\"\", inplace=True)# sinon nan sera compris comme une string non vide\n",
    "\n",
    "## retirer ce qui est dans HAL qui a un lien extérieur et qui est signalé en repository dans upw\n",
    "index2remove = df_final[ (df_final[\"linkExtId\"] != \"\") & (df_final[\"oa_repo_link\"] != \"\") ].index\n",
    "df_final.drop(index2remove, inplace = True)\n",
    "print(f\"nb DOI retiré car marqué 'open' dans HAL et repository dans upw {len(index2remove)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7f56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deduire la colonne todo\n",
    "df_final[\"todo\"] = df_final.apply(lambda row : deduce_todo(row), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98badb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Statistiques\n",
      "\n",
      "nb de DOI a traiter 1063\n",
      "mailto auteur pour appliquer LRN                        568\n",
      "creer/retrouver notice                                  266\n",
      "selon licence ajouter PDF editeur                       208\n",
      "verifier identifiants notice                              5\n",
      "recuperer pdf publisher et mailto auteur pour accord      5\n",
      "Name: todo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#retrait des colonnes inutiles \n",
    "df_final.drop(columns= [\"has_issn\", \"submitType\"], inplace = True)\n",
    "df_final.to_csv(\"data\\dois_a_traiter.csv\", index = False)\n",
    "#produire les statistiques brutes\n",
    "print(f\"\\n\\nStatistiques\\n\\nnb de DOI a traiter {len(df_final)}\\n{df_final['todo'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40b4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rendre la lecture dans libreOffice plus élégante avec l'ajout d'hyperliens\n",
    "df_final[\"doi\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://doi.org/\", row[\"doi\"], row[\"doi\"]), axis = 1)  \n",
    "df_final[\"halId\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://hal.archives-ouvertes.fr/\", row[\"halId\"], row[\"halId\"]), axis = 1)  \n",
    "df_final[\"oa_publisher_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_publisher_link\"], row[\"oa_publisher_link\"]), axis = 1)\t\n",
    "df_final[\"oa_repo_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_repo_link\"], row[\"oa_repo_link\"]), axis = 1)\t\n",
    "\n",
    "df_final.to_csv(\"data\\dois_a_traiter_formula.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ede349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
