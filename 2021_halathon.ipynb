{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeaea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanr_utils import *\n",
    "from casuhal_utils import *\n",
    "import pandas as pd, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eace86b",
   "metadata": {},
   "source": [
    "## 1. Récupérer les DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2532e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de DOI importés depuis fichier \t1283\n"
     ]
    }
   ],
   "source": [
    "## option A : utiliser un fichier local \n",
    "\n",
    "utiliser_fichier_local = True # True pour oui False pour non\n",
    "\n",
    "if utiliser_fichier_local : \n",
    "    ## un fichier local placé dans le dossier *data*\n",
    "    ## doit être un fichier .csv avec encodage utf8 et ',' comme séparateur\n",
    "    ## avec au moins une colonne *doi*\n",
    "    df_mydois = pd.read_csv(\"data\\scopus_2021.csv\", usecols=[\"doi\"])     \n",
    "    print(f\"nb de DOI importés depuis fichier \\t{len(df_mydois)}\")\n",
    "else : \n",
    "    df_mydois = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f72220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## option B : utiliser ScanR pour récupérer les DOIs\n",
    "\n",
    "utiliser_scanR = False # True pour oui False pour non \n",
    "# scanR inclut les publications jusqu'a 2020.\n",
    "# à univ. Paris les DOIs récents sont priorisés, donc dans un premier temps pas d'utilisation de ScanR\n",
    "\n",
    "if utiliser_scanR : \n",
    "\n",
    "    id_etab = \"0755976N\" # identifiant UAI de votre établissement\n",
    "    min_year = 2020 # l'année à partir de laquelle commencer la récupération. \n",
    "    # 2020 donne les publications de 2020. 2019 donne les publications de 2019 et 2020 etc.\n",
    "\n",
    "    df_scanr = get_publications_with_doi(id_etab, min_year)\n",
    "    df_scanr.drop(columns = [\"title\", \"year\"], inplace = True)\n",
    "    print(f\"nb de DOI récupérés de ScanR \\t{len(df_scanr)}\")\n",
    "    #df_scanr.to_csv(\"data\\doi_scanr.csv\", columns= [\"doi\"], index = False)\n",
    "    \n",
    "    # concatener et dédoublonner\n",
    "    df = pd.concat([df_mydois, df_scanr])\n",
    "    df[\"doi\"] = df[\"doi\"].str.lower() # doi en minuscule\n",
    "    df = df[ (~df['doi'].duplicated()) & (df[\"doi\"].notna())].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "else : \n",
    "    df = df_mydois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ceb691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb de DOI a traiter \t1283\n",
      " /!\\ temps estimé ~32 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\" nb de DOI a traiter \\t{len(df)}\")\n",
    "print(f\" /!\\ temps estimé ~{round(len(df) * 30/1200)} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d79c13",
   "metadata": {},
   "source": [
    "## 2. Enrichir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1285c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans HAL 1283\n",
      "hal 10% \n",
      "hal 20% \n",
      "hal 30% \n",
      "hal 40% \n",
      "hal 50% \n",
      "hal 60% \n",
      "hal 70% \n",
      "hal 80% \n",
      "hal 90% \n",
      "hal 100% \n",
      "hal 100%\n",
      "nb de DOI après retrait de ceux en TI Dans HAL 1112\n"
     ]
    }
   ],
   "source": [
    "## avec HAL\n",
    "df_hal = enrich_w_hal(df) # renseigner df[:50].copy() pour tester uniquement sur les 50 premiers DOI\n",
    "df_no_file = df_hal[ df_hal[\"submitType\"] != \"file\" ].copy()\n",
    "print(f\"nb de DOI après retrait de ceux en TI Dans HAL {len(df_no_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ef3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans upw \t1112\n",
      "upw 10% \n",
      "upw 20% \n",
      "upw 30% \n",
      "upw 40% \n",
      "upw 50% \n",
      "upw 60% \n",
      "upw 70% \n",
      "upw 80% \n",
      "upw 90% \n",
      "upw 100% \n",
      "upw 100%\n"
     ]
    }
   ],
   "source": [
    "## avec Unpaywall\n",
    "df_upw = enrich_w_upw(df_no_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79cff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permissions 100%\n"
     ]
    }
   ],
   "source": [
    "## avec Permissions\n",
    "df_permissions = enrich_w_permissions(df_upw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09e3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export des données brutes\n",
    "df_permissions.to_csv(\"data\\dois_hal_upw_perm.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2a3eb",
   "metadata": {},
   "source": [
    "## 3. Trier et Formater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f25ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI retiré car marqué 'open' dans HAL et repository dans upw 50\n"
     ]
    }
   ],
   "source": [
    "df_final = df_permissions\n",
    "df_final.fillna(\"\", inplace=True)# sinon nan sera compris comme une string non vide\n",
    "\n",
    "## retirer ce qui est dans HAL qui a un lien extérieur et qui est signalé en repository dans upw\n",
    "index2remove = df_final[ (df_final[\"linkExtId\"] != \"\") & (df_final[\"oa_repo_link\"] != \"\") ].index\n",
    "df_final.drop(index2remove, inplace = True)\n",
    "print(f\"nb DOI retiré car marqué 'open' dans HAL et repository dans upw {len(index2remove)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7f56c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Statistiques\n",
      "\n",
      "nb de DOI a traiter\t\t\t\t1062\n",
      "mailto auteur pour appliquer LRN                        564\n",
      "creer/retrouver notice                                  273\n",
      "selon licence ajouter PDF publisher                     204\n",
      "verifier identifiants notice                              5\n",
      "recuperer PDF publisher et mailto auteur pour accord      5\n",
      "Name: todo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# deduire la colonne todo\n",
    "df_final[\"todo\"] = df_final.apply(lambda row : deduce_todo(row), axis = 1)\n",
    "df_final.to_csv(\"data\\dois_a_traiter.csv\", index = False)\n",
    "#imprimer des statistiques brutes\n",
    "print(f\"\\nStatistiques\\n\\nnb de DOI a traiter\\t\\t\\t\\t{len(df_final)}\\n{df_final['todo'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b40b4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrait des colonnes inutiles \n",
    "df_final.drop(columns= [\"submitType\", \"has_issn\"], inplace = True)\n",
    "\n",
    "# rendre la lecture dans libreOffice plus élégante avec l'ajout d'hyperliens\n",
    "df_final[\"doi\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://doi.org/\", row[\"doi\"], row[\"doi\"]), axis = 1)  \n",
    "df_final[\"halId\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://hal.archives-ouvertes.fr/\", row[\"halId\"], row[\"halId\"]), axis = 1)  \n",
    "df_final[\"oa_publisher_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_publisher_link\"], row[\"oa_publisher_link\"]), axis = 1)\t\n",
    "df_final[\"oa_repo_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_repo_link\"], row[\"oa_repo_link\"]), axis = 1)\t\n",
    "\n",
    "df_final.to_csv(\"data\\dois_a_traiter_formules.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
