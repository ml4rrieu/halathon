{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeaea70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, json, numpy as np\n",
    "from scanr_utils import *\n",
    "from casuhal_utils import *\n",
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eace86b",
   "metadata": {},
   "source": [
    "## 1. R√©cup√©rer les DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2532e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de DOI import√©s depuis fichier \t400\n"
     ]
    }
   ],
   "source": [
    "## option A : utiliser un fichier local \n",
    "\n",
    "utiliser_fichier_local = True\n",
    "\n",
    "if utiliser_fichier_local : \n",
    "    ## un fichier local plac√© dans le dossier *data*\n",
    "    ## doit √™tre un fichier .csv avec encodage utf8 et ',' comme s√©parateur\n",
    "    ## avec au moins une colonne *doi* \n",
    "    ## precier le nom de cette colonne (DOI, doiId_s etc. )\n",
    "    doi_col_name = \"DOI\"\n",
    "    \n",
    "    df_mydois = pd.read_csv(\"data/2023-05-halathon-scopus-sante.csv\", usecols = [doi_col_name])\n",
    "    \n",
    "    # dans la suite du code la colonne doit √™tre nomm√©e doi\n",
    "    df_mydois.rename(columns = {doi_col_name : \"doi\"}, inplace = True)\n",
    "    \n",
    "    ## limiter le nombre de ligne/publication\n",
    "    df_mydois = df_mydois[:400]\n",
    "    print(f\"nb de DOI import√©s depuis fichier \\t{len(df_mydois)}\")\n",
    "else : \n",
    "    df_mydois = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f72220f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## option B : utiliser ScanR\n",
    "# les deux options peuvent √™tre valides, un d√©doublonnage sera alors effectu√©\n",
    "\n",
    "utiliser_scanR = False # True pour oui False pour non \n",
    "\n",
    "if utiliser_scanR : \n",
    "    \n",
    "    id_etab = \"180089047\" # identifiant UAI de votre √©tablissement\n",
    "    # UP 0755976N, Nantes 194409843, INRIA 180089047\n",
    "    min_year = 2020 # l'ann√©e √† partir de laquelle commencer la r√©cup√©ration. \n",
    "    # scanR inclut les publications jusqu'a 2020.\n",
    "    # 2020 donne les publications de 2020. 2019 donne les publications de 2019 et 2020 etc.\n",
    "\n",
    "    df_scanr = get_publications_with_doi(id_etab, min_year)\n",
    "    df_scanr.drop(columns = [\"title\", \"year\"], inplace = True)\n",
    "    print(f\"nb de DOI r√©cup√©r√©s de ScanR \\t{len(df_scanr)}\")\n",
    "    #df_scanr.to_csv(\"data\\doi_scanr.csv\", columns= [\"doi\"], index = False)\n",
    "    \n",
    "    # concatener et d√©doublonner\n",
    "    df = pd.concat([df_mydois, df_scanr])\n",
    "    df[\"doi\"] = df[\"doi\"].str.lower() # doi en minuscule\n",
    "    df = df[ (~df['doi'].duplicated()) & (df[\"doi\"].notna())].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "else : \n",
    "    df = df_mydois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ceb691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb de DOI a traiter \t400\n",
      " /!\\ temps estim√© ~13 minutes\n"
     ]
    }
   ],
   "source": [
    "# retrait des publications sans DOI\n",
    "df.dropna(subset=[\"doi\"], inplace = True)\n",
    "\n",
    "# feedback nb de DOI  et tps de traitement\n",
    "print(f\" nb de DOI a traiter \\t{len(df)}\")\n",
    "print(f\" /!\\ temps estim√© ~{round(len(df) * 40/1200)} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d79c13",
   "metadata": {},
   "source": [
    "## 2. Enrichir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1285c198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans HAL 400\n",
      "hal 10% \n",
      "hal 20% \n",
      "hal 30% \n",
      "hal 40% \n",
      "hal 50% \n",
      "hal 60% \n",
      "hal 70% \n",
      "hal 80% \n",
      "hal 90% \n",
      "hal 100%\n",
      "nb de DOI apr√®s retrait de ceux en TI dans HAL 352\n"
     ]
    }
   ],
   "source": [
    "# 2.1. pour chaque publications d√©duire la pr√©sence dans HAL\n",
    "df_hal = enrich_w_hal(df) # renseigner df[:50].copy() pour tester uniquement sur les 50 premiers DOI\n",
    "\n",
    "#retirer ce qui est d√©j√† d√©pos√© avec fichier\n",
    "df_no_file = df_hal[ df_hal[\"submitType\"] != \"file\" ].copy()\n",
    "print(f\"nb de DOI apr√®s retrait de ceux en TI dans HAL {len(df_no_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ef3e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI a verifier dans upw \t352\n",
      "upw 10% \n",
      "upw 20% \n",
      "upw 30% \n",
      "upw 40% \n",
      "upw 50% \n",
      "upw 60% \n",
      "upw 70% \n",
      "upw 80% \n",
      "upw 89% \n",
      "upw 99% \n",
      "upw 100%\n"
     ]
    }
   ],
   "source": [
    "# 2.2. pour chaque publications ajouter les informations d'acc√®s ouvert via Unpaywall\n",
    "df_upw = enrich_w_upw(df_no_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7c568d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remplacer nan/None par des champs vides\n",
    "df_upw[\"oa_repo_link\"].replace(np.nan, \"\", inplace = True)\n",
    "df_upw[\"oa_repo_link\"].replace(\"None\", \"\", inplace = True)\n",
    "df_upw[\"oa_publisher_license\"].replace(np.nan, \"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79cff8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1016/j.omtn.2023.03.012 publishedVersion can be shared üéâ\n",
      "10.1016/j.resplu.2023.100381 publishedVersion can be shared üéâ\n",
      "10.1016/j.jgar.2023.02.005 publishedVersion can be shared üéâ\n",
      "10.1016/j.resmer.2022.100981 acceptedVersion , no embargo\n",
      "10.1530/REP-22-0416 acceptedVersion , no embargo\n",
      "10.1200/JCO.22.00437 publishedVersion can be shared üéâ\n",
      "10.1177/19714009221109885 acceptedVersion , no embargo\n",
      "10.1093/bjd/ljac134 acceptedVersion , no embargo\n",
      "10.1093/gerona/glac234 acceptedVersion , no embargo\n",
      "10.1002/14651858.CD015490 acceptedVersion , no embargo\n",
      "10.1182/blood.2022016943 publishedVersion can be shared üéâ\n",
      "10.15252/emmm.202216320 publishedVersion can be shared üéâ\n",
      "doi problem w permissions 10.4244/EIJ-D-22-00723\n",
      "10.1002/jmd2.12358 publishedVersion can be shared üéâ\n",
      "10.1093/clinchem/hvac201 acceptedVersion , no embargo\n",
      "10.1016/j.banm.2022.10.019 acceptedVersion , no embargo\n",
      "10.1016/j.idnow.2023.01.001 acceptedVersion , no embargo\n",
      "10.1002/adbi.202200224 acceptedVersion , no embargo\n",
      "10.1136/thorax-2022-219086 acceptedVersion , no embargo\n",
      "10.1002/nop2.1394 publishedVersion can be shared üéâ\n",
      "10.1136/archdischild-2022-324321 acceptedVersion , no embargo\n",
      "10.1136/sextrans-2021-055364 acceptedVersion , no embargo\n",
      "10.1016/j.isci.2023.106019 publishedVersion can be shared üéâ\n",
      "10.1093/ejendo/lvad012 acceptedVersion , no embargo\n",
      "doi problem w permissions 10.1684/vir.2023.0985\n",
      "10.1128/jcm.01457-22 acceptedVersion , no embargo\n",
      "10.1128/aac.00871-22 acceptedVersion , no embargo\n",
      "10.1159/000525552 acceptedVersion , no embargo\n",
      "doi problem w permissions 10.1148/radiol.211658\n"
     ]
    }
   ],
   "source": [
    "# 2.3. ajouter les possibilit√©s de d√©p√¥t via l'API Permissions\n",
    "df_upw[\"deposit_condition\"] = df_upw.apply(lambda row : add_permissions(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09e3df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## export des donn√©es brutes\n",
    "df_upw.to_csv(\"data/raw__dois_hal_upw_perm.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2a3eb",
   "metadata": {},
   "source": [
    "## 3. Trier et Formater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f25ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb DOI retir√© car marqu√© 'open' dans HAL et repository dans upw 4\n"
     ]
    }
   ],
   "source": [
    "df_final = df_upw\n",
    "df_final.fillna(\"\", inplace = True) # sinon nan sera compris comme une string non vide\n",
    "\n",
    "## retirer ce qui est dans HAL qui a un lien ext√©rieur et qui est signal√© en repository dans upw\n",
    "index2remove = df_final[ (df_final[\"linkExtId\"] != \"\") & (df_final[\"oa_repo_link\"] != \"\") ].index\n",
    "df_final.drop(index2remove, inplace = True)\n",
    "print(f\"nb DOI retir√© car marqu√© 'open' dans HAL et repository dans upw {len(index2remove)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b7f56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduire la colonne todo\n",
    "df_final[\"todo\"] = df_final.apply(lambda row : deduce_todo(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e00e847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## retrait des colonnes non utilis√©es\n",
    "remove_cols = [\"submitType\", \"has_issn\"]\n",
    "for col in remove_cols : \n",
    "    if col in df_final.columns :\n",
    "        del df_final[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2681445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques\n",
      "\n",
      "nb de DOI a traiter\t\t\t348\n",
      "ecrire a l auteur pour appliquer la LRN                      144\n",
      "selon la licence ajouter le PDF editeur                      129\n",
      "creer ou retrouver la notice                                  63\n",
      "recuperer le PDF editeur et ecrire a l auteur pour accord      9\n",
      "verifier les identifiants de la notice                         2\n",
      "Name: todo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#imprimer des statistiques brutes\n",
    "print(f\"\\nStatistiques\\n\\nnb de DOI a traiter\\t\\t\\t{len(df_final)}\\n{df_final['todo'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c68955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doi', 'halId', 'linkExtId', 'upw_state', 'published_date',\n",
       "       'oa_publisher_license', 'oa_publisher_link', 'oa_repo_link',\n",
       "       'deposit_condition', 'todo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.to_csv(\"data\\dois_a_traiter.csv\", index = False)\n",
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c37e1cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rendre la lecture dans libreOffice plus √©l√©gante avec l'ajout d'hyperlien\n",
    "df_final[\"doi\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://doi.org/\", row[\"doi\"], row[\"doi\"]), axis = 1)  \n",
    "df_final[\"halId\"] = df_final.apply(lambda row : addCaclLinkFormula(\"https://hal.archives-ouvertes.fr/\", row[\"halId\"], row[\"halId\"]), axis = 1)  \n",
    "df_final[\"oa_publisher_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_publisher_link\"], row[\"oa_publisher_link\"]), axis = 1)\t\n",
    "df_final[\"oa_repo_link\"] = df_final.apply(lambda row : addCaclLinkFormula(\"\", row[\"oa_repo_link\"], row[\"oa_repo_link\"]), axis = 1)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8771959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## exporter les donn√©es sous forme de tableau pour libreOffice\n",
    "df_final.to_csv(\"data\\dois_a_traiter_formules.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c83c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
